{
  "app": {
    "title": "SAM 3D Body â†’ Unity FBX",
    "heading": "ğŸ§â€â™‚ï¸ SAM 3D Body â†’ Unity Humanoid FBX",
    "program_tab": "Program",
    "about_tab": "About",
    "features_title": "Features",
    "features": [
      "Generate Unity Humanoid-compatible FBX files from a single image",
      "Generate multi-frame animations from MP4 videos",
      "3D mesh + skeleton + **animation**"
    ],
    "usage_title": "Usage",
    "usage": [
      "Upload an image or MP4 video",
      "Click the \"Estimate Pose\" button",
      "(Optional) Download the generated JSON for future use, tuning refinement, etc.",
      "Click the \"Generate FBX\" button",
      "Download the generated FBX â†’ Import to Unity",
      "The following are optional features:",
      "Upload your own bboxes and camera intrinsics file from gta-link, boxmot, colmap",
      "For video, you may or may not want root motion for your armature - check the box if you do",
      "Apply standard mocap-style smoothing to the animation via Refinement. Enabled by default with some customizable settings."
    ]
  },
  "ui": {
    "profile": "ğŸ“Š Armature Model",
    "input_file": "ğŸ“ Image/Video File",
    "use_bbox": "ğŸ‘¥ Use BBOX File",
    "bbox_file": "ğŸ“ BBOX File",
    "num_people": "ğŸ‘¥ Number of People",
    "missing_bbox_behavior": "On Missing Frame",
    "missing_bbox_behavior_info": "What to do when bbox data is missing for a frame: Run Detection (use num_people to detect) or Skip Frame (skip pose estimation for that frame)",
    "fov_method": "ğŸ“· FOV Estimation Method",
    "fov_method_info": "Default: Built-in, runs every frame | File: Load from cameras.txt | Sample: Average from images",
    "fov_file": "ğŸ“ Camera Intrinsics File (COLMAP cameras.txt or MoGe format)",
    "sample_number": "ğŸ“Š Sample Number",
    "sample_number_info": "Number of images to sample and average for FOV estimation",
    "precision": "ğŸ›ï¸ Precision",
    "precision_info": "FP32 for best quality, BF16/FP16 for faster inference",
    "auto_run": "âš¡ Auto-Run Generate FBX (on Estimate Pose completion)",
    "use_root_motion": "ğŸ§­ Apply Root Motion",
    "auto_floor": "ğŸ§­ Auto-Floor",
    "auto_floor_info": "Offset the average pred_cam_t height to 0 so subjects stand above the floor",
    "include_mesh": "ğŸ­ Include Mesh",
    "include_extrinsics": "ğŸ“· Include Extrinsics",
    "use_personalized_body": "ğŸ‘¤ Use Personalized Body",
    "use_personalized_body_info": "Generate a personalized body mesh from estimation data. If unchecked, uses default LOD body.",
    "lod": "ğŸ“Š LOD",
    "lod_info": "Level of Detail for mesh (0-6)",
    "outlier_removal_percent": "ğŸ“Š Outlier Removal (%)",
    "outlier_removal_percent_info": "Percentage of outliers to remove from each tail (0-50)",
    "extrinsics_sample_rate": "ğŸ“Š Extrinsics Downsampling Rate",
    "extrinsics_sample_rate_info": "0 = auto (round(frame_count / extrinsics_count))",
    "extrinsics_scale": "ğŸ“ Extrinsics Scale",
    "extrinsics_scale_info": "0 = auto (placeholder; currently uses 1.0)",
    "extrinsics_invert_quaternion": "ğŸ” Invert Extrinsics Rotation",
    "extrinsics_invert_quaternion_info": "Treat qvec as cameraâ†’world instead of worldâ†’camera",
    "extrinsics_invert_translation": "ğŸ” Invert Extrinsics Translation",
    "extrinsics_invert_translation_info": "Treat tvec as cameraâ†’world instead of worldâ†’camera",
    "extrinsics_file": "ğŸ“ Extrinsics File (COLMAP images.txt)",
    "estimate_pose_btn": "ğŸ¯ Estimate Pose",
    "step_1_estimate_pose": "1. Estimate Pose",
    "generate_fbx_btn": "ğŸš€ Generate FBX",
    "step_2_generate_fbx": "2. Generate FBX",
    "options_title": "Options",
    "estimation_options_title": "Estimation Options",
    "fbx_options_title": "FBX Options",
    "pose_json_file": "ğŸ“„ Pose Estimation JSON",
    "pose_json_file_info": "Upload a pose estimation JSON file, or it will be auto-populated after estimation",
    "output_files": "ğŸ“¦ Generated Files",
    "developer_options": "Developer Options",
    "export_personalized_body_obj": "ğŸ§ª Export Personalized Body Obj",
    "cancel_current_jobs": "ğŸ›‘ Cancel Current Jobs",
    "cancel_current_jobs_info": "Stop any running Estimate Pose or Generate FBX job (requires queue).",
    "cli_generator_title": "CLI Generator",
    "cli_generator_info": "Create a command template from the current UI options. Replace <INPUT_FILE> and other placeholders before running. Note: mesh and refinement options are not available in the CLI yet.",
    "generate_cli_btn": "ğŸ§° Generate CLI",
    "cli_command_label": "CLI Command",
    "cli_command_info": "Template command for batch runs",
    "refinement": {
      "title": "Refinement",
      "enabled": "Enabled",
      "enabled_info": "Enable refinement processing (occurs after generation)",
      "load_config": "Load Config",
      "load_config_info": "Upload a JSON configuration file",
      "save_config": "Save Config",
      "save_config_info": "Download current configuration as JSON",
      "save_config_btn": "Save Configuration",
      "global_settings": "Refinement Global Settings",
      "sections": {
        "root": "Root",
        "hands": "Hands",
        "fingers": "Fingers",
        "head": "Head",
        "legs": "Legs",
        "arms": "Arms",
        "default": "Default"
      },
      "max_pos_speed": "Max Positional Speed",
      "max_pos_speed_info": "Maximum positional speed (units/sec) for spike detection",
      "max_pos_accel": "Max Positional Acceleration",
      "max_pos_accel_info": "Maximum positional acceleration (units/secÂ²) for spike detection",
      "max_ang_speed_deg": "Max Angular Speed (Degrees)",
      "max_ang_speed_deg_info": "Maximum angular speed (deg/sec) for spike detection",
      "max_ang_accel_deg": "Max Angular Acceleration (Degrees)",
      "max_ang_accel_deg_info": "Maximum angular acceleration (deg/secÂ²) for spike detection",
      "method": "Method",
      "method_info": "Smoothing filter method",
      "method_one_euro": "One Euro",
      "method_ema": "EMA",
      "method_butterworth": "Butterworth",
      "cutoff_hz": "Cutoff Frequency (Hz)",
      "cutoff_hz_info": "Cutoff frequency for EMA/Butterworth filters",
      "one_euro_min_cutoff": "One Euro Min Cutoff (Hz)",
      "one_euro_min_cutoff_info": "Minimum cutoff frequency for One Euro filter",
      "one_euro_beta": "One Euro Beta",
      "one_euro_beta_info": "Speed coefficient for One Euro filter",
      "one_euro_d_cutoff": "One Euro Derivative Cutoff (Hz)",
      "one_euro_d_cutoff_info": "Derivative cutoff frequency for One Euro filter",
      "root_cutoff_xy_hz": "Root Cutoff XY (Hz)",
      "root_cutoff_xy_hz_info": "Cutoff frequency for horizontal (XY) root motion",
      "root_cutoff_z_hz": "Root Cutoff Z (Hz)",
      "root_cutoff_z_hz_info": "Cutoff frequency for vertical (Z) root motion",
      "interpolate_missing_keyframes": "Interpolate Missing Keyframes",
      "interpolate_missing_keyframes_info": "When enabled, missing frames (where no people were detected) will be interpolated using slerp for rotations and linear interpolation for vectors. When disabled, missing frames are skipped during refinement.",
      "use_foot_planting": "Use Foot Planting",
      "use_foot_planting_info": "Enable foot planting to adjust root motion based on foot contact, reducing jitter and creating more natural walking/running motion",
      "foot_planting": {
        "title": "Foot Planting",
        "foot_contact_velocity_threshold": "Foot Contact Velocity Threshold (m/s)",
        "foot_contact_velocity_threshold_info": "Foot is considered 'planted' if its velocity is below this threshold",
        "foot_contact_min_height": "Foot Contact Min Height (m)",
        "foot_contact_min_height_info": "Foot must be below this height (Y coordinate) to be considered in contact",
        "contact_smoothing_window": "Contact Smoothing Window",
        "contact_smoothing_window_info": "Number of frames to use for smoothing contact detection (reduces flickering)",
        "blend_factor": "Blend Factor",
        "blend_factor_info": "How much to blend foot-based root adjustment with original root motion (0-1, higher = more adjustment)",
        "root_smoothing_window": "Root Smoothing Window",
        "root_smoothing_window_info": "Number of frames to use for smoothing the adjusted root motion",
        "use_mid_foot": "Use Mid Foot",
        "use_mid_foot_info": "Use mid_foot (average of heel/toes) instead of ankle for foot position"
      }
    }
  },
  "progress": {
    "processing_keyframes": "ğŸ“¦ Processing keyframes...",
    "processing_person": "ğŸ“¦ Processing person...",
    "reexporting": "ğŸ”„ Re-exporting from saved results...",
    "applying_refinement": "Applying refinement to estimation results...",
    "preparing_fbx_data": "Preparing FBX data...",
    "preprocessing_complete": "Pre-processing complete",
    "refining_person": "Refining person {person_index} of {total_people}",
    "refinement_complete": "Refinement complete",
    "applying_poses": "Applying poses: {frame_num}/{total_frames}",
    "estimating_frame": "Estimating frame {frame_index} of {total_frames}"
  },
  "errors": {
    "error_occurred": "An error occurred ({error_type}): {error_msg}",
    "error_occurred_no_msg": "An error occurred: {error_type}",
    "bbox_file_required": "BBOX file must be provided when 'use bbox' is enabled",
    "num_people_required": "Number of people must be greater than 0",
    "camera_intrinsics_required": "Camera intrinsics file must be provided when FOV method is 'File'",
    "fov_estimator_required": "FOV estimator must be loaded to use 'Sample' method. Please ensure FOV estimator is initialized.",
    "pose_json_file_required": "Please provide a pose estimation JSON file"
  }
}
